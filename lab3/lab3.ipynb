{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "# #os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "# #import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"dataset/training_set\"\n",
    "test_dir=\"dataset/test_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1./255,\n",
    "#                                  rotation_range=10,\n",
    "#                                  width_shift_range=0.1,\n",
    "#                                  height_shift_range=0.1,\n",
    "#                                  shear_range=0.1,\n",
    "#                                  zoom_range=0.1,\n",
    "#                                  horizontal_flip=True,\n",
    "#                                  fill_mode='nearest'\n",
    "                                 )\n",
    "test_datagen= ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64,64),\n",
    "    batch_size=1,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "test_generator=train_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(64,64),\n",
    "    batch_size=1,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod():\n",
    "    model=models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu',input_shape=(64,64,3)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    #model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.7241 - accuracy: 0.4750 - val_loss: 0.7100 - val_accuracy: 0.4200\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.7022 - accuracy: 0.4850 - val_loss: 0.6863 - val_accuracy: 0.4900\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.7059 - accuracy: 0.5050 - val_loss: 0.6974 - val_accuracy: 0.4800\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6937 - accuracy: 0.5400 - val_loss: 0.6903 - val_accuracy: 0.5400\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6958 - accuracy: 0.5600 - val_loss: 0.6529 - val_accuracy: 0.6000\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6964 - accuracy: 0.6050 - val_loss: 0.6376 - val_accuracy: 0.5600\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6786 - accuracy: 0.5700 - val_loss: 0.6253 - val_accuracy: 0.6500\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.7054 - accuracy: 0.5500 - val_loss: 0.6800 - val_accuracy: 0.5200\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6902 - accuracy: 0.5300 - val_loss: 0.6080 - val_accuracy: 0.7000\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6901 - accuracy: 0.5650 - val_loss: 0.6260 - val_accuracy: 0.6300\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6849 - accuracy: 0.5300 - val_loss: 0.6977 - val_accuracy: 0.5800\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6906 - accuracy: 0.5750 - val_loss: 0.7826 - val_accuracy: 0.6300\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.7033 - accuracy: 0.5750 - val_loss: 0.5095 - val_accuracy: 0.4700\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6927 - accuracy: 0.5350 - val_loss: 0.7245 - val_accuracy: 0.5900\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6778 - accuracy: 0.5750 - val_loss: 0.5473 - val_accuracy: 0.5200\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 0.6732 - accuracy: 0.6050 - val_loss: 0.7397 - val_accuracy: 0.5700\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6426 - accuracy: 0.6100 - val_loss: 0.6747 - val_accuracy: 0.5500\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6787 - accuracy: 0.5750 - val_loss: 0.7679 - val_accuracy: 0.5500\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6727 - accuracy: 0.5950 - val_loss: 0.4368 - val_accuracy: 0.6000\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6653 - accuracy: 0.6500 - val_loss: 0.6248 - val_accuracy: 0.5900\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6880 - accuracy: 0.5300 - val_loss: 0.5377 - val_accuracy: 0.6000\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6662 - accuracy: 0.6300 - val_loss: 0.6978 - val_accuracy: 0.5400\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6668 - accuracy: 0.6350 - val_loss: 0.9395 - val_accuracy: 0.5800\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.7000 - accuracy: 0.5000 - val_loss: 0.6170 - val_accuracy: 0.5600\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6814 - accuracy: 0.5900 - val_loss: 0.7453 - val_accuracy: 0.6400\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6511 - accuracy: 0.6350 - val_loss: 0.2803 - val_accuracy: 0.5800\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6677 - accuracy: 0.5950 - val_loss: 0.6456 - val_accuracy: 0.6000\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6938 - accuracy: 0.6150 - val_loss: 0.2448 - val_accuracy: 0.4600\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6764 - accuracy: 0.5500 - val_loss: 0.6384 - val_accuracy: 0.6800\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6732 - accuracy: 0.6050 - val_loss: 0.7997 - val_accuracy: 0.6000\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6448 - accuracy: 0.6900 - val_loss: 0.3117 - val_accuracy: 0.6100\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6479 - accuracy: 0.6250 - val_loss: 0.4962 - val_accuracy: 0.5900\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.7005 - accuracy: 0.6050 - val_loss: 0.6865 - val_accuracy: 0.5900\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.6670 - accuracy: 0.6050 - val_loss: 0.6750 - val_accuracy: 0.6300\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6664 - accuracy: 0.6300 - val_loss: 0.8031 - val_accuracy: 0.7200\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.6492 - accuracy: 0.6550 - val_loss: 0.6529 - val_accuracy: 0.6500\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6402 - accuracy: 0.6000 - val_loss: 0.1419 - val_accuracy: 0.5500\n",
      "Epoch 38/60\n",
      " 41/200 [=====>........................] - ETA: 1s - loss: 0.6372 - accuracy: 0.6585"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-fbee82e4c0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     epochs=60,)\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model=mod()\n",
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=100,\n",
    "    steps_per_epoch=200,\n",
    "    epochs=60,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(1,len(acc)+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs,acc,'b',label=\"Training acc\")\n",
    "plt.plot(epochs,val_acc,'r',label=\"val acc\")\n",
    "plt.title(\"Training and validation acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs,loss,'b',label=\"Training loss\")\n",
    "plt.plot(epochs,val_loss,'r',label=\"val loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
